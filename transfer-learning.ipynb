{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\levan\\anaconda3\\envs\\rts\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import keras as K\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['dry_asphalt_severe',\n",
    "           'dry_asphalt_slight',\n",
    "           'dry_asphalt_smooth',\n",
    "           'dry_concrete_severe',\n",
    "           'dry_concrete_slight',\n",
    "           'dry_concrete_smooth',\n",
    "           'water_asphalt_severe',\n",
    "           'water_asphalt_slight',\n",
    "           'water_asphalt_smooth',\n",
    "           'water_concrete_severe',\n",
    "           'water_concrete_slight',\n",
    "           'water_concrete_smooth',\n",
    "           'wet_asphalt_severe',\n",
    "           'wet_asphalt_slight',\n",
    "           'wet_asphalt_smooth',\n",
    "           'wet_concrete_severe',\n",
    "           'wet_concrete_slight',\n",
    "           'wet_concrete_smooth']\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "num_classes =len(classes)\n",
    "\n",
    "dataset_path = './datasets'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "def generators(shape, preprocessing): \n",
    "    '''Create the training and validation datasets for \n",
    "    a given image shape.\n",
    "    '''\n",
    "    imgdatagen = ImageDataGenerator(\n",
    "        preprocessing_function = preprocessing,\n",
    "        horizontal_flip = True, \n",
    "        validation_split = 0.1,\n",
    "    )\n",
    "\n",
    "    height, width = shape\n",
    "\n",
    "    train_dataset = imgdatagen.flow_from_directory(\n",
    "        dataset_path,\n",
    "        target_size = (height, width), \n",
    "        classes = classes,\n",
    "        batch_size = batch_size,\n",
    "        subset = 'training', \n",
    "    )\n",
    "\n",
    "    val_dataset = imgdatagen.flow_from_directory(\n",
    "        dataset_path,\n",
    "        target_size = (height, width), \n",
    "        classes = classes,\n",
    "        batch_size = batch_size,\n",
    "        subset = 'validation'\n",
    "    )\n",
    "    return train_dataset, val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 16200 images belonging to 18 classes.\n",
      "Found 1800 images belonging to 18 classes.\n"
     ]
    }
   ],
   "source": [
    "train_dataset, val_dataset = generators(\n",
    "    (224, 224), preprocessing=K.applications.resnet50.preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = K.Input(shape=(224, 224, 3))\n",
    "\n",
    "\"\"\"Loading the ResNet50 model with pre-trained ImageNet weights\n",
    "\"\"\"\n",
    "resnet = K.applications.ResNet50(weights='imagenet',\n",
    "                                 include_top=False, input_tensor=inputs)\n",
    "\n",
    "for layer in resnet.layers[:170]:\n",
    "    layer.trainable = False\n",
    "\n",
    "model = K.models.Sequential()\n",
    "model.add(K.layers.Lambda(lambda x: tf.image.resize(x, (224, 224))))\n",
    "model.add(resnet)\n",
    "model.add(K.layers.GlobalAveragePooling2D())\n",
    "model.add(K.layers.BatchNormalization())\n",
    "model.add(K.layers.Dense(256, activation='relu'))\n",
    "model.add(K.layers.BatchNormalization())\n",
    "model.add(K.layers.Dense(128, activation='relu'))\n",
    "model.add(K.layers.Dropout(0.3))\n",
    "model.add(K.layers.BatchNormalization())\n",
    "model.add(K.layers.Dense(64, activation='relu'))\n",
    "model.add(K.layers.Dropout(0.3))\n",
    "model.add(K.layers.BatchNormalization())\n",
    "model.add(K.layers.Dense(num_classes, activation='softmax'))\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=K.optimizers.RMSprop(learning_rate=2e-5),\n",
    "              metrics=['accuracy'])\n",
    "checkpointer = K.callbacks.ModelCheckpoint(filepath='rts-checkpoint.keras',\n",
    "                                           monitor=\"val_accuracy\",\n",
    "                                           verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_dataset, validation_data=val_dataset,\n",
    "                    epochs=10, callbacks=[checkpointer])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()\n",
    "\n",
    "model.save(\"rts.keras\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rts",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
